{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import contractions\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from datasets import load_dataset\n",
    "import torch.nn.functional as F\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "ps = PorterStemmer()\n",
    "os.environ[\"TORCH_TEXT_DISABLE_CPP_EXTENSIONS\"] = \"1\"\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from Material import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    return re.sub(r'<.*?>', '', text)\n",
    "def remove_urls1(text) :\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "def remove_urls2(text) :\n",
    "    return re.sub(r'www.\\S+', '', text) \n",
    "def remove_emojis(text):\n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "                                    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                                    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                                    u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                                    u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                                    u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                                    u\"\\U00002702-\\U000027B0\"\n",
    "                                    u\"\\U00002702-\\U000027B0\"\n",
    "                                    u\"\\U000024C2-\\U0001F251\"\n",
    "                                    u\"\\U0001f926-\\U0001f937\"\n",
    "                                    u\"\\U00010000-\\U0010ffff\"\n",
    "                                    u\"\\u2640-\\u2642\"\n",
    "                                    u\"\\u2600-\\u2B55\"\n",
    "                                    u\"\\u200d\"\n",
    "                                    u\"\\u23cf\"\n",
    "                                    u\"\\u23e9\"\n",
    "                                    u\"\\u231a\"\n",
    "                                    u\"\\ufe0f\"  # dingbats\n",
    "                                    u\"\\u3030\"\n",
    "                                    \"]+\", flags=re.UNICODE)\n",
    "        return emoji_pattern.sub(r'', text)\n",
    "def remove_mentions(text):\n",
    "    return re.sub(r'@[A-Za-z0-9_]+', '', text)\n",
    "def LowerCase(text):\n",
    "    return text.lower()\n",
    "def expand_contractions(text):\n",
    "    return contractions.fix(text)\n",
    "def remove_non_ascii(text):\n",
    "    return text.encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "def Remove_text_within_sqbrackets (text) :\n",
    "    return re.sub(r'\\[.*?\\]', ' ', text)\n",
    "def Remove_special_characters (text) :\n",
    "    return re.sub(r'[()!?]', ' ', text)\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "def Replace_multiple_spaces_with_a_single_space (text):\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "def normalize_repeated_chars(text):\n",
    "    return re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
    "def remove_numbers(text):\n",
    "    return re.sub(r'\\d+', '', text)\n",
    "def remove_stopwords(text):\n",
    "    return ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
    "def lemmatize_text(text):\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "def stem_text(text):\n",
    "    return ' '.join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Initial cleaning\n",
    "    text = remove_html_tags(text)\n",
    "    text = remove_urls1(text)\n",
    "    text = remove_urls2(text)\n",
    "    text = remove_emojis(text)\n",
    "    text = remove_mentions(text)\n",
    "    \n",
    "    # Standardization\n",
    "    text = LowerCase(text)\n",
    "    text = expand_contractions(text)\n",
    "    text = remove_non_ascii(text)\n",
    "    text = Remove_text_within_sqbrackets(text)\n",
    "    \n",
    "    # Remove special characters and punctuation\n",
    "    text = Remove_special_characters(text)\n",
    "    text = remove_punctuation(text)\n",
    "    \n",
    "    # Handling spaces and repeated characters\n",
    "    text = Replace_multiple_spaces_with_a_single_space(text)\n",
    "    text = normalize_repeated_chars(text)\n",
    "    text = remove_numbers(text)\n",
    "    \n",
    "    # Remove stopwords \n",
    "    #text = remove_stopwords(text)\n",
    "    \n",
    "    # Stemming or Lemmatization (choose one)\n",
    "    # text = stem_text(text)\n",
    "    #text = lemmatize_text(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text, v, max_seq_len):\n",
    "    # Pass the text as a string directly\n",
    "    tokens = v.text_to_tensor(text, max_seq_len)\n",
    "    tokens = tokens.unsqueeze(0)\n",
    "    return tokens.to(DEVICE)\n",
    "# Step 4: Function to predict class probabilities and the predicted class\n",
    "def predict_text(text, model, v, max_seq_len):\n",
    "    processed_text = preprocess_text(text)\n",
    "    tokens = tokenize_text(processed_text, v, max_seq_len)\n",
    "    # Ensure no gradients are calculated during prediction\n",
    "    with torch.no_grad():\n",
    "        output,_ = model(tokens)  # Raw logits from the model\n",
    "        probabilities = F.softmax(output, dim=1).cpu().numpy()[0]  # Convert to probabilities\n",
    "        predicted_class = probabilities.argmax()  # Get class index with highest probability\n",
    "    return probabilities, predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PosNegNeu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = Vocabulary([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 200 #400, 500\n",
    "EMBED_DIM = 128 #256, 256\n",
    "HIDDEN_DIM = 32 #128, 128\n",
    "NUM_LAYERS = 2 # 4, 3\n",
    "DROPOUT = 0.1 #0.2, 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMClassifierBi(\n",
       "  (embedding): Embedding(30522, 128, padding_idx=0)\n",
       "  (lstm): LSTM(128, 32, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "  (attention): Attention(\n",
       "    (attn): Linear(in_features=64, out_features=1, bias=True)\n",
       "    (softmax): Softmax(dim=1)\n",
       "  )\n",
       "  (fc): Linear(in_features=64, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTMClassifierBi(v,len(v.vocab),EMBED_DIM, HIDDEN_DIM, 3, NUM_LAYERS, dropout=DROPOUT).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Load only the weights (state_dict)\n",
    "model.load_state_dict(torch.load(\"PosNegNeu_model.pth\", map_location=DEVICE))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"PosNegNeu_model_tokenizer.pkl\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Probabilities: [2.5316521e-07 2.1057552e-08 9.9999976e-01]\n",
      "Predicted Class: positive\n"
     ]
    }
   ],
   "source": [
    "label_map = {0:'negative', 1:'neutral', 2:'positive'}\n",
    "\n",
    "# Step 5: Example prediction\n",
    "text ='i am good'\n",
    "probabilities, predicted_label = predict_text(text, model, v, MAX_SEQ_LEN)\n",
    "\n",
    "\n",
    "print(\"Class Probabilities:\", probabilities)\n",
    "print(\"Predicted Class:\", label_map[predicted_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suicide_Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_DIM = 256\n",
    "HIDDEN_DIM = 64\n",
    "NUM_LAYERS = 2 \n",
    "DROPOUT = 0.1 \n",
    "MAX_SEQ_LEN = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMClassifierBi(\n",
       "  (embedding): Embedding(30522, 256, padding_idx=0)\n",
       "  (lstm): LSTM(256, 64, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "  (attention): Attention(\n",
       "    (attn): Linear(in_features=128, out_features=1, bias=True)\n",
       "    (softmax): Softmax(dim=1)\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = Vocabulary([])\n",
    "model = LSTMClassifierBi(v,len(v.vocab),EMBED_DIM, HIDDEN_DIM, 2, NUM_LAYERS, dropout=DROPOUT).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Load only the weights (state_dict)\n",
    "model.load_state_dict(torch.load(\"Suicide_model.pth\", map_location=DEVICE))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Suicide_model_tokenizer.pkl\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Probabilities: [1.1356238e-07 9.9999988e-01]\n",
      "Predicted Class: Suicide\n"
     ]
    }
   ],
   "source": [
    "label_map = {0:'Non Suicide', 1:'Suicide'}\n",
    "\n",
    "# Step 5: Example prediction\n",
    "text = \"I am gonna kill my self\"\n",
    "probabilities, predicted_label = predict_text(text, model, v, MAX_SEQ_LEN)\n",
    "\n",
    "print(\"Class Probabilities:\", probabilities)\n",
    "print(\"Predicted Class:\", label_map[predicted_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facebook Emo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_DIM = 128 #256, 256\n",
    "HIDDEN_DIM = 64 #128, 128\n",
    "NUM_LAYERS = 2 # 4, 3\n",
    "DROPOUT = 0.1 #0.2, 0.5\n",
    "MAX_SEQ_LEN = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMClassifierBi(\n",
       "  (embedding): Embedding(30522, 128, padding_idx=0)\n",
       "  (lstm): LSTM(128, 64, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "  (attention): Attention(\n",
       "    (attn): Linear(in_features=128, out_features=1, bias=True)\n",
       "    (softmax): Softmax(dim=1)\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=6, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = Vocabulary([])\n",
    "model = LSTMClassifierBi(v,len(v.vocab),EMBED_DIM, HIDDEN_DIM, 6, NUM_LAYERS, dropout=DROPOUT).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Load only the weights (state_dict)\n",
    "model.load_state_dict(torch.load(r\"facebookEmo_model.pth\", map_location=DEVICE))\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"facebookEmo_model_tokenizer.pkl\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Probabilities: [8.2023054e-02 8.1911081e-01 3.6644936e-04 9.3319237e-02 5.0887861e-03\n",
      " 9.1686103e-05]\n",
      "Predicted Class: joy\n"
     ]
    }
   ],
   "source": [
    "label_map = {0:'sadness', 1:'joy', 2:'love', 3:'anger', 4:'fear', 5:'surprise'}\n",
    "\n",
    "# Step 5: Example prediction\n",
    "text = 'wow'\n",
    "probabilities, predicted_label = predict_text(text, model, v, MAX_SEQ_LEN)\n",
    "\n",
    "\n",
    "print(\"Class Probabilities:\", probabilities)\n",
    "print(\"Predicted Class:\", label_map[predicted_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Litigious Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_DIM = 128 #256, 256\n",
    "HIDDEN_DIM = 32 #128, 128\n",
    "NUM_LAYERS = 2 # 4, 3\n",
    "DROPOUT = 0.1 #0.2, 0.5\n",
    "MAX_SEQ_LEN = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMClassifierBi(\n",
       "  (embedding): Embedding(30522, 128, padding_idx=0)\n",
       "  (lstm): LSTM(128, 32, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "  (attention): Attention(\n",
       "    (attn): Linear(in_features=64, out_features=1, bias=True)\n",
       "    (softmax): Softmax(dim=1)\n",
       "  )\n",
       "  (fc): Linear(in_features=64, out_features=4, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v= Vocabulary([])\n",
    "model = LSTMClassifierBi(v,len(v.vocab),EMBED_DIM, HIDDEN_DIM, 4, NUM_LAYERS, dropout=DROPOUT).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Load only the weights (state_dict)\n",
    "model.load_state_dict(torch.load(\"Models&Tokenizers\\litigious_model.pth\", map_location=DEVICE))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Models&Tokenizers\\litigious_model_tokenizer.pkl\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Probabilities: [9.9998534e-01 1.2048759e-05 2.6228622e-06 3.8594610e-11]\n",
      "Predicted Class: litigious\n"
     ]
    }
   ],
   "source": [
    "label_map = {0:'litigious', 1:'negative', 2:'positive', 3:'uncertainty'}\n",
    "\n",
    "# Step 5: Example prediction\n",
    "text = 'wow'\n",
    "\n",
    "probabilities, predicted_label = predict_text(text, model, v, MAX_SEQ_LEN)\n",
    "\n",
    "\n",
    "print(\"Class Probabilities:\", probabilities)\n",
    "print(\"Predicted Class:\", label_map[predicted_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_DIM = 128 #256, 256\n",
    "HIDDEN_DIM = 32 #128, 128\n",
    "NUM_LAYERS = 1 # 4, 3\n",
    "DROPOUT = 0.2 #0.2, 0.5\n",
    "MAX_SEQ_LEN = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ONE BY ONE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTMClassifierBi(\n",
       "  (embedding): Embedding(30522, 128, padding_idx=0)\n",
       "  (lstm): LSTM(128, 32, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (attention): Attention(\n",
       "    (attn): Linear(in_features=64, out_features=1, bias=True)\n",
       "    (softmax): Softmax(dim=1)\n",
       "  )\n",
       "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v= Vocabulary([])\n",
    "model = LSTMClassifierBi(v,len(v.vocab),EMBED_DIM, HIDDEN_DIM, 2, NUM_LAYERS, dropout=DROPOUT).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Load only the weights (state_dict)\n",
    "model.load_state_dict(torch.load(\"Models&Tokenizers\\depression_model.pth\", map_location=DEVICE))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Models&Tokenizers\\depression_model_tokenizer.pkl\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Probabilities: [6.9089659e-04 9.9930906e-01]\n",
      "Predicted Class: Depression\n"
     ]
    }
   ],
   "source": [
    "label_map = {0:'Non-Depression', 1:'Depression'}\n",
    "\n",
    "# Step 5: Example prediction\n",
    "text = 'open discussion between the transfer portal and the nil will the become obsolete as an organization and governing body hopelessness gopokes loyalandtrue'\n",
    "\n",
    "probabilities, predicted_label = predict_text(text, model, v, MAX_SEQ_LEN)\n",
    "\n",
    "\n",
    "print(\"Class Probabilities:\", probabilities)\n",
    "print(\"Predicted Class:\", label_map[predicted_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Model Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_DIM = 128 #256, 256\n",
    "HIDDEN_DIM = 64 #128, 128\n",
    "NUM_LAYERS = 3 # 4, 3\n",
    "DROPOUT = 0.2 #0.2, 0.5\n",
    "MAX_SEQ_LEN = 450"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMClassifierBi(\n",
       "  (embedding): Embedding(30522, 128, padding_idx=0)\n",
       "  (lstm): LSTM(128, 64, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (attention): Attention(\n",
       "    (attn): Linear(in_features=128, out_features=1, bias=True)\n",
       "    (softmax): Softmax(dim=1)\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=7, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v= Vocabulary([])\n",
    "model = LSTMClassifierBi(v,len(v.vocab),EMBED_DIM, HIDDEN_DIM, 7, NUM_LAYERS, dropout=DROPOUT).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Load only the weights (state_dict)\n",
    "model.load_state_dict(torch.load(\"main2_model.pth\", map_location=DEVICE))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"main2_model_tokenizer.pkl\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Probabilities: [9.9998486e-01 1.6958934e-06 1.4108380e-06 2.7860273e-07 1.3248567e-06\n",
      " 1.0169501e-05 2.3955613e-07]\n",
      "Predicted Class: anxiety\n"
     ]
    }
   ],
   "source": [
    "label_map = {0:'anxiety', 1:'bipolar', 2:'depression', 3:'normal', 4:'personality disorder', 5:'stress', 6:'suicidal'}\n",
    "\n",
    "# Step 5: Example prediction\n",
    "text = 'my mind is a neverending cycle of worry and even the simplest tasks feel insurmountable i am consumed by fear and doubt and every decision feels like a minefield waiting to explode anxiety has a grip on me and i am powerless to break free from its relentless hold my thoughts race like a runaway train and i cannot seem to find a way to slow down and catch my breath i am trapped in a whirlwind of fear and uncertainty and i cannot seem to find a way to escape my heart pounds in my chest and my'\n",
    "\n",
    "probabilities, predicted_label = predict_text(text, model, v, MAX_SEQ_LEN)\n",
    "\n",
    "\n",
    "print(\"Class Probabilities:\", probabilities)\n",
    "print(\"Predicted Class:\", label_map[predicted_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main model New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_DIM = 256 #256, 256\n",
    "HIDDEN_DIM = 256 #128, 128\n",
    "NUM_LAYERS = 3 # 4, 3\n",
    "DROPOUT = 0.3 #0.2, 0.5\n",
    "MAX_SEQ_LEN = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMClassifierBi(\n",
       "  (embedding): Embedding(30522, 256, padding_idx=0)\n",
       "  (lstm): LSTM(256, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "  (attention): Attention(\n",
       "    (attn): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (softmax): Softmax(dim=1)\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=5, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v= Vocabulary([])\n",
    "model = LSTMClassifierBi(v,len(v.vocab),EMBED_DIM, HIDDEN_DIM, 5, NUM_LAYERS, dropout=DROPOUT).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Load only the weights (state_dict)\n",
    "model.load_state_dict(torch.load(\"Models&Tokenizers\\main_model.pth\", map_location=DEVICE))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Models&Tokenizers\\main_model_tokenizer.pkl\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Probabilities: [1.0000000e+00 4.3307749e-10 4.2600562e-10 6.4689670e-10 8.0607278e-11]\n",
      "Predicted Class: ADHD\n"
     ]
    }
   ],
   "source": [
    "label_map = {0:'ADHD', 1:'OCD', 2:'aspergers', 3:'depression', 4:'ptsd'}\n",
    "\n",
    "# Step 5: Example prediction\n",
    "text = 'a few months ago i was accepted into this full time software engineering fellowship and it is made me realize that i cannot work sustainably to save my life it is so hard to prioritize my time when i get so hyper focused on each task or just on something completely irrelevant i was just diagnosed last year so i am still learning how to learn with adhd but i feel even more pressure to work so much harder to prove my worth because i am a black woman in engineering i have been falling into a really unhealthy cycle of taking more than my prescribed dose to work longer because i would waste so much time during the day and it is just gotten out of hand it is like you go your whole life feeling so dumb and incompetent and now you do not and you just want to learn everything all the time but that is just not sustainable or normal anyways i do not know sorry for the rant i am just tired do not know what to do'\n",
    "\n",
    "probabilities, predicted_label = predict_text(text, model, v, MAX_SEQ_LEN)\n",
    "\n",
    "\n",
    "print(\"Class Probabilities:\", probabilities)\n",
    "print(\"Predicted Class:\", label_map[predicted_label])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
